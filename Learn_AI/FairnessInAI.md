# Fairness in AI (AI 공정성)

## 1. 개요 (Overview)
Fairness in AI(AI 공정성)는 인공지능 모델이 특정 집단(인종, 성별, 나이 등)에 대해 차별적인 결과를 내놓지 않도록 보장하는 기술 및 연구 분야입니다.

## 2. 편향의 원인 (Sources of Bias)
- **데이터 편향**: 학습 데이터 자체가 역사적인 차별이나 불균형을 포함하고 있는 경우. (예: CEO 이미지 검색 시 남성 사진만 나오는 경우)
- **알고리즘 편향**: 모델의 구조나 목적 함수가 특정 패턴을 선호하도록 설계된 경우.

## 3. 주요 지표 (Metrics)
- **Demographic Parity (인구 통계적 동등성)**: 모델의 예측 결과(예: 대출 승인율)가 보호받아야 할 속성(예: 성별)에 상관없이 동일해야 함을 의미합니다.
- **Equalized Odds (동등한 기회)**: 실제 정답이 긍정인 경우(예: 실제 상환 능력이 있는 사람)에 대해, 모델이 긍정으로 예측할 확률이 집단 간에 동일해야 합니다.

## 4. 해결 방안
- **Pre-processing**: 학습 데이터를 수정하여 편향을 제거합니다. (예: 데이터 리샘플링)
- **In-processing**: 학습 과정에서 공정성 제약 조건을 추가하여 모델을 학습시킵니다.
- **Post-processing**: 모델의 예측 결과를 보정하여 공정성을 확보합니다.

## 5. 관련 문서
- [AIEthics](./AIEthics.md)
- [Data Preprocessing](./DataPreprocessing.md)
